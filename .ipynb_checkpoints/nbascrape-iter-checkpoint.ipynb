{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basketball-reference.com Web Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will pull and assemble a table of all the game stats of each player drafted into the NBA. Three separate tables will be created: A 'draft' table which summarizes all the players drafted and player specific information such as draft position, height, weight, and more. The second table will assemble all game logs found for the player found under international leagues and college basketball for all years prior to their draft year. The third table is all game stats for the player in the NBA. The datasets are not 100% inclusive due to some missing player info on basketball-reference.com. \n",
    "\n",
    "This code is flexible in that periods can be combined and not all the desired periods need to be run in the same session. Subsequent scrapings will be combined with previous scrapes and any overlapping years and or duplicates will be eliminated :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set file path and select years and then run all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/erler/OneDrive/Documents/Random Data Sets/Basketball/'\n",
    "#choose years span (though note that it runs extremely slow for many years at a time)\n",
    "first_year = 2003\n",
    "last_year = 2003\n",
    "drafts_file_name = 'draft1'\n",
    "preNBA_file_name = 'pre1'\n",
    "gamelog_file_name = 'nba1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required packages\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "from itertools import cycle \n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta \n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "sauce = urllib.request.urlopen('https://www.basketball-reference.com/draft/NBA_2018.html').read()\n",
    "soup = bs.BeautifulSoup(sauce, 'lxml')\n",
    "\n",
    "def make_inches(x):\n",
    "    try: \n",
    "        return float(x.split('-')[0])*12+float(x.split('-')[1])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "def linkfix(x, testlink): #normalize links for website quirks\n",
    "    if x[-1] != '/':\n",
    "        x+='/'\n",
    "    if x[:len(testlink)] == testlink:\n",
    "        pass\n",
    "    else:\n",
    "        x=testlink+x\n",
    "    return x\n",
    "\n",
    "def minplayed(x): #convert minutes played into datetime format\n",
    "    if ':' in x:\n",
    "        a = pd.to_timedelta(float(x.split(':')[0]), unit= 'min')\n",
    "        b = pd.to_timedelta(float(x.split(':')[1]), unit= 's')\n",
    "        return a+b\n",
    "    else:\n",
    "        return pd.to_timedelta(float(x), unit='min')  \n",
    "\n",
    "def ages(x): #convert age to float\n",
    "        a = float(x.split('-')[0])\n",
    "        b = float(x.split('-')[1])/365\n",
    "        return a+b    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create table of all NBA picks for a given timespan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8881 seconds\n"
     ]
    }
   ],
   "source": [
    "ticB1 = time.perf_counter()\n",
    "years = [i for i in range(first_year, last_year+1)]\n",
    "p1 = 'https://www.basketball-reference.com/draft/NBA_'\n",
    "p2 = '.html'\n",
    "drafts = []\n",
    "for i in years:\n",
    "    x = pd.read_html(p1+str(i)+p2)[0].droplevel(0, axis=1) #get each years draft class\n",
    "    x['Year'] = i #add year to table\n",
    "    x = x.loc[x.Rk.str.isnumeric()==True] #filter for headers and non-data\n",
    "    x['pro_link']=np.nan #new\n",
    "    sauce = urllib.request.urlopen(p1+str(i)+p2).read() #import html data\n",
    "    soup = bs.BeautifulSoup(sauce, 'lxml') \n",
    "    table = soup.table #find table\n",
    "    table_rows = table.find_all('tr') #find table rows\n",
    "    for tr in table_rows: #find table links for players page and put in a list\n",
    "        try:\n",
    "            pick = int(tr.find_all('td')[0].get('csk')) #get pick number\n",
    "        except:\n",
    "            pass\n",
    "        a = tr.find_all('a')\n",
    "        for url in a: \n",
    "            if url.get('href')[:9] == '/players/':\n",
    "                x.loc[x['Pk']==str(pick), 'pro_link'] = url.get('href')\n",
    "                                \n",
    "    drafts.append(x) #append each year\n",
    "    \n",
    "drafts = pd.concat(drafts)  #concat each df/year into one dataframe\n",
    "\n",
    "#make a player name column that matches url use\n",
    "drafts.Player = drafts.Player.replace({' ': '-'}, regex=True).str.lower() \n",
    "drafts['Player_url'] = [unicodedata.normalize('NFD', t).encode('ascii', 'ignore').decode('utf-8') for t in drafts.Player]\n",
    "drafts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "tocB1 = time.perf_counter()\n",
    "print(f\"{tocB1 - ticB1:0.4f} seconds\") #revised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve urls for college or international league gamelogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.8851 seconds\n"
     ]
    }
   ],
   "source": [
    "ticB2 = time.perf_counter()\n",
    "\n",
    "drafts['cbb_gamelogs'] = np.nan #set destination column\n",
    "for j in range(len(drafts)+1): #for all players\n",
    "    leagues = []\n",
    "    seasons = []\n",
    "    try:\n",
    "        sauce = urllib.request.urlopen('https://www.basketball-reference.com'+drafts.pro_link[j]) #url main page of each player\n",
    "        soup = bs.BeautifulSoup(sauce, 'lxml') \n",
    "\n",
    "        drafts.loc[j, 'Pro_height'] = soup.find_all('span',itemprop=\"height\")[0].text\n",
    "        drafts.loc[j, 'Pro_weight'] = re.sub(\"[^0-9]\",'', soup.find_all('span',itemprop=\"weight\")[0].text)\n",
    "        drafts.loc[j, 'DOB'] = [i.get('data-birth') for i in soup.find_all('span') if i.get('data-birth')][0]\n",
    "\n",
    "        a = soup.find_all('a') #find all links\n",
    "        testlink='https://www.basketball-reference.com'  \n",
    "        for url in a:\n",
    "            try: #retrieve link to gamelogs for college games from pro profile\n",
    "                if url.get('href')[:45] == 'https://www.sports-reference.com/cbb/players/':\n",
    "                    linkfull = url.get('href')\n",
    "                    sauce = urllib.request.urlopen(linkfull) #url main page of each cbb player\n",
    "                    soup = bs.BeautifulSoup(sauce, 'lxml')\n",
    "                    drafts.loc[j, 'cbb_height'] = soup.find_all('span',itemprop=\"height\")[0].text #get cbb height\n",
    "                    drafts.loc[j, 'cbb_weight'] = re.sub(\"[^0-9]\",'', soup.find_all('span',itemprop=\"weight\")[0].text) #get cbb weight\n",
    "                    link = linkfull[:-5]+'/gamelog/' #adjust urls to get gamelogs\n",
    "                    leagues.append(linkfix(link, 'https://www.sports-reference.com'))                     \n",
    "\n",
    "                #retrieve links to gamelogs for international league games from pro profile\n",
    "                if url.get('href')[:59] == 'https://www.basketball-reference.com/international/players/':\n",
    "                    link = url.get('href') #get all links to intl play\n",
    "                    sauce2 = urllib.request.urlopen(link) #get html\n",
    "                    soup2 = bs.BeautifulSoup(sauce2, 'lxml') \n",
    "                    a2 = soup2.find_all('a') #find all links to leagues for each player from intl page\n",
    "                    for url2 in a2: #get the links for gamelogs\n",
    "                        try:\n",
    "                            if 'gamelog' in url2.get('href'):\n",
    "                                x = url2.get('href')\n",
    "                                leagues.append(linkfix(x, testlink))\n",
    "\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                #Retrieve NBA gamelogs        \n",
    "                if 'gamelog' in url.get('href'):\n",
    "                    x = url.get('href')\n",
    "                    seasons.append(linkfix(x, testlink))   \n",
    "\n",
    "            except:\n",
    "                pass\n",
    "    except:\n",
    "        pass    \n",
    "        \n",
    "    leagues=set(leagues) #eliminate duplicates\n",
    "    seasons=set(seasons) #eliminate duplicates\n",
    "    drafts.loc[j, 'cbb_gamelogs'] = [leagues] #store in player table\n",
    "    drafts.loc[j, 'pro_gamelogs'] = [seasons] #store in player table\n",
    "    #print(j)\n",
    "    \n",
    "tocB2 = time.perf_counter()\n",
    "print(f\"{tocB2 - ticB2:0.4f} seconds\")  #revised "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formating\n",
    "drafts = drafts.drop([drafts.loc[drafts.Year.isnull()].index[0]], axis=0)\n",
    "\n",
    "drafts.Pro_height = drafts.Pro_height.astype(str)   \n",
    "drafts.Pro_height = drafts.Pro_height.apply(lambda x: make_inches(x))\n",
    "drafts.loc[drafts.cbb_height.isna()!=True, 'cbb_height'] = drafts.loc[drafts.cbb_height.isna()!=True, 'cbb_height'].apply(lambda x: make_inches(x))\n",
    "drafts.DOB = drafts.DOB.astype('datetime64')\n",
    "\n",
    "drafts.Year = pd.to_datetime(drafts.Year, format='%Y') #dt format\n",
    "drafts.Year = drafts.Year.apply(lambda x: x+pd.to_timedelta(180, unit='days')) #estimate draft date (used for cutoff purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save file\n",
    "drafts.to_csv(path+drafts_file_name+str(first_year)+'_'+str(last_year)+'.csv', index=None) #save to folder in case failure\n",
    "drafts=pd.DataFrame()\n",
    "files = os.listdir(path)\n",
    "files = [f for f in files if drafts_file_name in f]\n",
    "for f in files:\n",
    "    drafts_current = pd.read_csv(path+f)\n",
    "    drafts = pd.concat([drafts, drafts_current])\n",
    "\n",
    "drafts = drafts.drop_duplicates()\n",
    "drafts.to_csv(path+drafts_file_name+'.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble pre-NBA gamelogs into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if drafts table needs to be loaded and formatting needs to be restored\n",
    "drafts = pd.read_csv(path+drafts_file_name+'.csv')\n",
    "drafts['cbb_gamelogs'] = drafts['cbb_gamelogs'].apply(lambda x: eval(x))\n",
    "drafts['pro_gamelogs'] = drafts['pro_gamelogs'].apply(lambda x: eval(x))\n",
    "drafts.Year = pd.to_datetime(drafts.Year) #dt format\n",
    "drafts.DOB = pd.to_datetime(drafts.DOB) #dt format\n",
    "\n",
    "#limit data scrape to desired years range\n",
    "drafts_iter = drafts.loc[(pd.DatetimeIndex(drafts.Year).year.astype(int)>=first_year)&(pd.DatetimeIndex(drafts.Year).year.astype(int)<=last_year)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259.6742 seconds\n"
     ]
    }
   ],
   "source": [
    "ticB3 = time.perf_counter()\n",
    "\n",
    "stats = [] #destination list\n",
    "\n",
    "for i in range(len(drafts_iter)+1):\n",
    "    try:\n",
    "        for q in drafts.loc[i, 'cbb_gamelogs']: #for each league\n",
    "            x = pd.read_html(q)[0] #pull in gamelogs table\n",
    "            x['League'] = 'NCAA' if q.split('/')[-2] == 'gamelog' else q.split('/')[-2] #league name\n",
    "            #conform headers\n",
    "            x.rename(columns={'School': 'Team', 'Unnamed: 7':'W/L', 'Unnamed: 5':'W/L', 'Unnamed: 4':'Location', 'Unnamed: 3':'Location'}, inplace=True)\n",
    "            x['Player']=drafts.loc[i,'Player'] #player name\n",
    "            x['DOB']=drafts.loc[i,'DOB'] #player name\n",
    "            if x.Rk.dtype != 'O':        #remove junk\n",
    "                x = x.loc[x.Rk.isna()!=True]\n",
    "                stats.append(x)\n",
    "            else:\n",
    "                x = x.loc[x.Rk.str.isdigit()==True]\n",
    "                stats.append(x)\n",
    "    except:\n",
    "        pass \n",
    "    #print(i)\n",
    "Predraft_game_stats = pd.concat(stats) #combine dataframes\n",
    "\n",
    "tocB3 = time.perf_counter()\n",
    "\n",
    "print(f\"{tocB3 - ticB3:0.4f} seconds\")  #revised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erler\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: DeprecationWarning: Numeric-style type codes are deprecated and will result in an error in the future.\n"
     ]
    }
   ],
   "source": [
    "#Combine previous scrapes and current into one file \n",
    "\n",
    "#formatting\n",
    "Predraft_game_stats.Date = pd.to_datetime(Predraft_game_stats.Date)\n",
    "Predraft_game_stats.Rk = pd.to_numeric(Predraft_game_stats.Rk)\n",
    "Predraft_game_stats[Predraft_game_stats.loc[:,'FG':'PTS'].columns.values] = Predraft_game_stats[Predraft_game_stats.loc[:,'FG':'PTS'].columns.values].astype('float64')\n",
    "Predraft_game_stats = Predraft_game_stats.convert_dtypes(infer_objects=True)   \n",
    "\n",
    "Predraft_game_stats['MP'] = Predraft_game_stats['MP'].astype(str)\n",
    "Predraft_game_stats['MP'] = Predraft_game_stats['MP'].apply(lambda x: minplayed(x))\n",
    "Predraft_game_stats.Date = Predraft_game_stats.Date.astype('datetime64')\n",
    "\n",
    "Predraft_game_stats = pd.merge(Predraft_game_stats, drafts[['Player', 'DOB', 'Year']], how='left', left_on=['Player', 'DOB'], right_on=['Player', 'DOB'], copy=False, validate='m:m')\n",
    "Predraft_game_stats['Year'] = pd.to_datetime(Predraft_game_stats.Year)\n",
    "\n",
    "Predraft_game_stats = Predraft_game_stats.loc[Predraft_game_stats.Date<Predraft_game_stats.Year] #elimate intl stats after draft day\n",
    "\n",
    "#force int64 to float64 for cooperation with statsmodel package\n",
    "for i in Predraft_game_stats.columns:\n",
    "    if Predraft_game_stats[i].dtype == 'Int64':\n",
    "        Predraft_game_stats[i] = Predraft_game_stats[i].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save file\n",
    "Predraft_game_stats.to_csv(path+preNBA_file_name+str(first_year)+'_'+str(last_year)+'.csv', index=None)\n",
    "Predraft_game_stats = pd.DataFrame()\n",
    "files = os.listdir(path)\n",
    "files = [f for f in files if preNBA_file_name in f]\n",
    "for f in files:\n",
    "    Predraft_game_stats_current = pd.read_csv(path+f)\n",
    "    Predraft_game_stats = pd.concat([Predraft_game_stats, Predraft_game_stats_current])\n",
    "\n",
    "Predraft_game_stats = Predraft_game_stats.drop_duplicates()\n",
    "Predraft_game_stats.to_csv(path+preNBA_file_name+'.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble NBA gamelogs into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if drafts table needs to be loaded and formatting needs to be restored\n",
    "drafts = pd.read_csv(path+drafts_file_name+'.csv')\n",
    "drafts['cbb_gamelogs'] = drafts['cbb_gamelogs'].apply(lambda x: eval(x))\n",
    "drafts['pro_gamelogs'] = drafts['pro_gamelogs'].apply(lambda x: eval(x))\n",
    "drafts.Year = pd.to_datetime(drafts.Year) #dt format\n",
    "drafts.DOB = pd.to_datetime(drafts.DOB) #dt format\n",
    "\n",
    "#limit data scrape to desired years range\n",
    "drafts_iter = drafts.loc[(pd.DatetimeIndex(drafts.Year).year.astype(int)>=first_year)&(pd.DatetimeIndex(drafts.Year).year.astype(int)<=last_year)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147.6251 seconds\n"
     ]
    }
   ],
   "source": [
    "ticB3 = time.perf_counter()\n",
    "\n",
    "NBA_stats = [] #destination list\n",
    "\n",
    "for i in range(len(drafts_iter)+1):\n",
    "    try:\n",
    "        for q in drafts.loc[i, 'pro_gamelogs']: #for each gamelog url\n",
    "            x = pd.read_html(q)[7] #get table\n",
    "            #conform column names\n",
    "            x.rename(columns={'Unnamed: 7':'W/L', 'Unnamed: 8':'W/L', 'Unnamed: 5':'Location', 'Unnamed: 3':'Location'}, inplace=True)\n",
    "            x.rename(columns=dict(zip(list(x.columns[x.columns.str.contains('Playoffs')==True]), cycle(['Date']))), inplace=True) \n",
    "            x['Player']=drafts.loc[i,'Player'] #get player name\n",
    "            x['DOB']=drafts.loc[i,'DOB'] #get DOB\n",
    "            if x.Rk.dtype != 'O':  #remove junk rows      \n",
    "                x = x.loc[x.Rk.isna()!=True]\n",
    "                NBA_stats.append(x)\n",
    "            else:\n",
    "                x = x.loc[x.Rk.str.isdigit()==True]\n",
    "                NBA_stats.append(x)\n",
    "    except:\n",
    "        pass \n",
    "    #print(i)\n",
    "NBA_game_stats = pd.concat(NBA_stats) #combine tables\n",
    "NBA_game_stats = NBA_game_stats.loc[NBA_game_stats.MP.str.match(r'[^0-9]')!=True]\n",
    "tocB3 = time.perf_counter()\n",
    "\n",
    "print(f\"{tocB3 - ticB3:0.4f} seconds\")  #revised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBA_game_stats.drop(['Unnamed: 31'], axis=1, inplace=True) #remove unneeded cols\n",
    "NBA_game_stats['MP'] = NBA_game_stats['MP'].apply(lambda x: minplayed(x)) \n",
    "NBA_game_stats.Date = NBA_game_stats.Date.astype('datetime64')\n",
    "\n",
    "NBA_game_stats['DOB'] = NBA_game_stats['DOB'].astype('datetime64')    \n",
    "NBA_game_stats.loc[NBA_game_stats['Age'].isna()!=True,'Age'] = NBA_game_stats.loc[NBA_game_stats['Age'].isna()!=True,'Age'].apply(lambda x: ages(x))\n",
    "NBA_game_stats['Age'] = NBA_game_stats['Age'].astype(float)\n",
    "NBA_game_stats = NBA_game_stats.merge(drafts[['Player', 'DOB', 'Year']], how = 'left', left_on=['Player', 'DOB'], right_on=['Player', 'DOB'], copy=False) #Bring in DOB (keep)\n",
    "NBA_game_stats.loc[NBA_game_stats['Age'].isna()==True,'Age'] = ((NBA_game_stats.loc[NBA_game_stats.Age.isna()==True,'Date']-NBA_game_stats.loc[NBA_game_stats.Age.isna()==True,'DOB'])/np.timedelta64(1,'Y'))\n",
    "\n",
    "NBA_game_stats['Years_pro'] = (NBA_game_stats.Date-NBA_game_stats.Year.astype('datetime64'))/np.timedelta64(1,'Y')\n",
    "NBA_game_stats.Years_pro = NBA_game_stats.Years_pro - NBA_game_stats.Years_pro.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erler\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (32) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#save file\n",
    "NBA_game_stats.to_csv(path+gamelog_file_name+str(first_year)+'_'+str(last_year)+'.csv', index=None) #save to folder in case failure\n",
    "NBA_game_stats=pd.DataFrame()\n",
    "files = os.listdir(path)\n",
    "files = [f for f in files if gamelog_file_name in f]\n",
    "for f in files:\n",
    "    NBAp_current = pd.read_csv(path+f)\n",
    "    NBA_game_stats = pd.concat([NBA_game_stats, NBAp_current])\n",
    "\n",
    "NBA_game_stats = NBA_game_stats.drop_duplicates()\n",
    "NBA_game_stats.to_csv(path+gamelog_file_name+'.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjust draft year back to year now that only now that calculations are complete\n",
    "\n",
    "drafts = pd.read_csv(path+drafts_file_name+'.csv')\n",
    "drafts.Year = pd.to_datetime(drafts.Year)\n",
    "drafts['Year'] = pd.DatetimeIndex(drafts.Year).year\n",
    "drafts.to_csv(path+drafts_file_name+'.csv', index=None)\n",
    "\n",
    "pre = pd.read_csv(path+preNBA_file_name+'.csv')\n",
    "pre['Draft_year'] = pd.to_datetime(pre.Year)\n",
    "pre['Draft_year'] = pd.DatetimeIndex(pre.Draft_year).year\n",
    "pre = pre.drop(['Year'], axis=1)\n",
    "pre.to_csv(path+preNBA_file_name+'.csv', index=None)\n",
    "\n",
    "nba = pd.read_csv(path+gamelog_file_name+'.csv')\n",
    "nba['Draft_year'] = pd.to_datetime(nba.Year)\n",
    "nba['Draft_year'] = pd.DatetimeIndex(nba.Draft_year).year\n",
    "nba = nba.drop(['Year'], axis=1)\n",
    "nba.to_csv(path+gamelog_file_name+'.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
