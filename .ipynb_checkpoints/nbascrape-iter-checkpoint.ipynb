{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basketball-reference.com Web Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will pull and assemble a table of all the game stats of each player drafted into the NBA. 3 seperate tables will be created: A 'draft' table which summerizes all the players drafted and player specific information such as draft position, height, weight, and more.The second table will assemble all game logs found for the player found under international leagues and college basketball for all years prior to their draft year. The third table is all game stats for the player in the NBA. The datasets are not 100% inclusive due to some missing player info on basketball-reference.com. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required packages\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "from itertools import cycle \n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta \n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "sauce = urllib.request.urlopen('https://www.basketball-reference.com/draft/NBA_2018.html').read()\n",
    "soup = bs.BeautifulSoup(sauce, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set file path and select years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/erler/OneDrive/Documents/Random Data Sets/'\n",
    "#choose years span (though note that it runs extremely slow for many years at a time)\n",
    "first_year = 2005\n",
    "last_year = 2019 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create table of all NBA picks for a given timespan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.2558 seconds\n"
     ]
    }
   ],
   "source": [
    "ticB1 = time.perf_counter()\n",
    "years = [i for i in range(first_year, last_year+1)]\n",
    "p1 = 'https://www.basketball-reference.com/draft/NBA_'\n",
    "p2 = '.html'\n",
    "drafts = []\n",
    "for i in years:\n",
    "    x = pd.read_html(p1+str(i)+p2)[0].droplevel(0, axis=1) #get each years draft class\n",
    "    x['Year'] = i #add year to table\n",
    "    x = x.loc[x.Rk.str.isnumeric()==True] #filter for headers and non-data\n",
    "    x['pro_link']=np.nan #new\n",
    "    sauce = urllib.request.urlopen(p1+str(i)+p2).read() #import html data\n",
    "    soup = bs.BeautifulSoup(sauce, 'lxml') \n",
    "    table = soup.table #find table\n",
    "    table_rows = table.find_all('tr') #find table rows\n",
    "    for tr in table_rows: #find table links for players page and put in a list\n",
    "        try:\n",
    "            pick = int(tr.find_all('td')[0].get('csk')) #get pick number\n",
    "        except:\n",
    "            pass\n",
    "        a = tr.find_all('a')\n",
    "        for url in a: \n",
    "            if url.get('href')[:9] == '/players/':\n",
    "                x.loc[x['Pk']==str(pick), 'pro_link'] = url.get('href')\n",
    "                                \n",
    "    drafts.append(x) #append each year\n",
    "    \n",
    "drafts = pd.concat(drafts)  #concat each df/year into one dataframe\n",
    "\n",
    "#make a player name column that matches url use\n",
    "drafts.Player = drafts.Player.replace({' ': '-'}, regex=True).str.lower() \n",
    "drafts['Player_url'] = [unicodedata.normalize('NFD', t).encode('ascii', 'ignore').decode('utf-8') for t in drafts.Player]\n",
    "drafts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "tocB1 = time.perf_counter()\n",
    "print(f\"{tocB1 - ticB1:0.4f} seconds\") #revised\n",
    "#print(f\"{tocA1 - ticA1:0.4f} seconds\") #original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve urls for college or international league gamelogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4366.2399 seconds\n"
     ]
    }
   ],
   "source": [
    "ticB2 = time.perf_counter()\n",
    "\n",
    "def linkfix(x, testlink): #normalize links for website quirks\n",
    "    if x[-1] != '/':\n",
    "        x+='/'\n",
    "    if x[:len(testlink)] == testlink:\n",
    "        pass\n",
    "    else:\n",
    "        x=testlink+x\n",
    "    return x\n",
    "\n",
    "drafts['cbb_gamelogs'] = np.nan #set destination column\n",
    "for j in range(len(drafts)+1): #for all players\n",
    "    leagues = []\n",
    "    seasons = []\n",
    "    try:\n",
    "        sauce = urllib.request.urlopen('https://www.basketball-reference.com'+drafts.pro_link[j]) #url main page of each player\n",
    "        soup = bs.BeautifulSoup(sauce, 'lxml') \n",
    "\n",
    "        drafts.loc[j, 'Pro_height'] = soup.find_all('span',itemprop=\"height\")[0].text\n",
    "        drafts.loc[j, 'Pro_weight'] = re.sub(\"[^0-9]\",'', soup.find_all('span',itemprop=\"weight\")[0].text)\n",
    "        drafts.loc[j, 'DOB'] = [i.get('data-birth') for i in soup.find_all('span') if i.get('data-birth')][0]\n",
    "\n",
    "        a = soup.find_all('a') #find all links\n",
    "        testlink='https://www.basketball-reference.com'  \n",
    "        for url in a:\n",
    "            try: #retrieve link to gamelogs for college games from pro profile\n",
    "                if url.get('href')[:45] == 'https://www.sports-reference.com/cbb/players/':\n",
    "                    linkfull = url.get('href')\n",
    "                    sauce = urllib.request.urlopen(linkfull) #url main page of each cbb player\n",
    "                    soup = bs.BeautifulSoup(sauce, 'lxml')\n",
    "                    drafts.loc[j, 'cbb_height'] = soup.find_all('span',itemprop=\"height\")[0].text #get cbb height\n",
    "                    drafts.loc[j, 'cbb_weight'] = re.sub(\"[^0-9]\",'', soup.find_all('span',itemprop=\"weight\")[0].text) #get cbb weight\n",
    "                    link = linkfull[:-5]+'/gamelog/' #adjust urls to get gamelogs\n",
    "                    leagues.append(linkfix(link, 'https://www.sports-reference.com'))                     \n",
    "\n",
    "                #retrieve links to gamelogs for international league games from pro profile\n",
    "                if url.get('href')[:59] == 'https://www.basketball-reference.com/international/players/':\n",
    "                    link = url.get('href') #get all links to intl play\n",
    "                    sauce2 = urllib.request.urlopen(link) #get html\n",
    "                    soup2 = bs.BeautifulSoup(sauce2, 'lxml') \n",
    "                    a2 = soup2.find_all('a') #find all links to leagues for each player from intl page\n",
    "                    for url2 in a2: #get the links for gamelogs\n",
    "                        try:\n",
    "                            if 'gamelog' in url2.get('href'):\n",
    "                                x = url2.get('href')\n",
    "                                leagues.append(linkfix(x, testlink))\n",
    "\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                #Retrieve NBA gamelogs        \n",
    "                if 'gamelog' in url.get('href'):\n",
    "                    x = url.get('href')\n",
    "                    seasons.append(linkfix(x, testlink))   \n",
    "\n",
    "            except:\n",
    "                pass\n",
    "    except:\n",
    "        pass    \n",
    "        \n",
    "    leagues=set(leagues) #eliminate duplicates\n",
    "    seasons=set(seasons) #eliminate duplicates\n",
    "    drafts.loc[j, 'cbb_gamelogs'] = [leagues] #store in player table\n",
    "    drafts.loc[j, 'pro_gamelogs'] = [seasons] #store in player table\n",
    "    #print(j)\n",
    "    \n",
    "tocB2 = time.perf_counter()\n",
    "print(f\"{tocB2 - ticB2:0.4f} seconds\")  #revised\n",
    "\n",
    "#print(f\"{tocA2 - ticA2:0.4f} seconds\")  #original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formating\n",
    "drafts = drafts.drop([drafts.loc[drafts.Year.isnull()].index[0]], axis=0)\n",
    "#drafts['cbb_gamelogs'] = drafts['cbb_gamelogs'].apply(lambda x: eval(x))\n",
    "#drafts['pro_gamelogs'] = drafts['pro_gamelogs'].apply(lambda x: eval(x))\n",
    "#drafts.drop(['pro_link','cbb_gamelogs', 'pro_gamelogs', 'Rk'], axis=1, inplace=True)\n",
    "#knock off second justin jackson (use unique url going forward)\n",
    "#drafts = drafts.drop_duplicates(subset=['Player'], keep='first')\n",
    "\n",
    "def make_inches(x):\n",
    "    try: \n",
    "        return float(x.split('-')[0])*12+float(x.split('-')[1])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "drafts.Pro_height = drafts.Pro_height.astype(str)   \n",
    "drafts.Pro_height = drafts.Pro_height.apply(lambda x: make_inches(x))\n",
    "drafts.loc[drafts.cbb_height.isna()!=True, 'cbb_height'] = drafts.loc[drafts.cbb_height.isna()!=True, 'cbb_height'].apply(lambda x: make_inches(x))\n",
    "drafts.DOB = drafts.DOB.astype('datetime64')\n",
    "\n",
    "drafts.Year = pd.to_datetime(drafts.Year.astype(int), format='%Y') #dt format\n",
    "drafts.Year = drafts.Year.apply(lambda x: x+pd.to_timedelta(180, unit='days')) #estimate draft date (used for cutoff purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save file just in case the next steps stall out\n",
    "drafts.to_csv(path+'drafts'+'.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble pre-NBA gamelogs into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticB3 = time.perf_counter()\n",
    "\n",
    "stats = [] #destination list\n",
    "\n",
    "for i in range(len(drafts)+1):\n",
    "    try:\n",
    "        for q in drafts.loc[i, 'cbb_gamelogs']: #for each league\n",
    "            x = pd.read_html(q)[0] #pull in gamelogs table\n",
    "            x['League'] = 'NCAA' if q.split('/')[-2] == 'gamelog' else q.split('/')[-2] #league name\n",
    "            #conform headers\n",
    "            x.rename(columns={'School': 'Team', 'Unnamed: 7':'W/L', 'Unnamed: 5':'W/L', 'Unnamed: 4':'Location', 'Unnamed: 3':'Location'}, inplace=True)\n",
    "            x['Player']=drafts.loc[i,'Player'] #player name\n",
    "            x['DOB']=drafts.loc[i,'DOB'] #player name\n",
    "            if x.Rk.dtype != 'O':        #remove junk\n",
    "                x = x.loc[x.Rk.isna()!=True]\n",
    "                stats.append(x)\n",
    "            else:\n",
    "                x = x.loc[x.Rk.str.isdigit()==True]\n",
    "                stats.append(x)\n",
    "    except:\n",
    "        pass \n",
    "    print(i)\n",
    "Predraft_game_stats = pd.concat(stats) #combine dataframes\n",
    "\n",
    "tocB3 = time.perf_counter()\n",
    "\n",
    "print(f\"{tocB3 - ticB3:0.4f} seconds\")  #revised\n",
    "\n",
    "#print(f\"{tocA3 - ticA3:0.4f} seconds\")  #original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formatting\n",
    "Predraft_game_stats.Date = pd.to_datetime(Predraft_game_stats.Date)\n",
    "Predraft_game_stats.Rk = pd.to_numeric(Predraft_game_stats.Rk)\n",
    "Predraft_game_stats[Predraft_game_stats.loc[:,'FG':'PTS'].columns.values] = Predraft_game_stats[Predraft_game_stats.loc[:,'FG':'PTS'].columns.values].astype('float64')\n",
    "Predraft_game_stats.convert_dtypes(infer_objects=False).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erler\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (34) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Combine previous scrapes and current into one file \n",
    "\n",
    "Predraft_stats.Rk = pd.to_numeric(Predraft_stats.Rk)\n",
    "Predraft_stats[Predraft_stats.loc[:,'FG':'PTS'].columns.values] = Predraft_stats[Predraft_stats.loc[:,'FG':'PTS'].columns.values].astype('float64')\n",
    "Predraft_stats = Predraft_stats.convert_dtypes(infer_objects=True)\n",
    "\n",
    "def minplayed(x):\n",
    "    if ':' in x:\n",
    "        a = pd.to_timedelta(float(x.split(':')[0]), unit= 'min')\n",
    "        b = pd.to_timedelta(float(x.split(':')[1]), unit= 's')\n",
    "        return a+b\n",
    "    else:\n",
    "        return pd.to_timedelta(float(x), unit='min')     \n",
    "\n",
    "Predraft_stats['MP'] = Predraft_stats['MP'].apply(lambda x: minplayed(x))\n",
    "Predraft_stats.Date = Predraft_stats.Date.astype('datetime64')\n",
    "\n",
    "# Predraft_stats = pd.merge(Predraft_stats, drafts[['Player', 'DOB', 'Year']], how='left', \n",
    "#                           left_on=['Player', 'DOB'], right_on=['Player', 'DOB'], validate='m:1')\n",
    "\n",
    "##delete once after next scraping\n",
    "Predraft_stats = pd.merge(Predraft_stats, drafts[['Player', 'DOB', 'Year']], how='left', left_on=['Player'], right_on=['Player'], validate='m:m')\n",
    "Predraft_stats.loc[(Predraft_stats.Player=='justin-jackson') & (Predraft_stats.Team=='Maryland'),'DOB'] = drafts.loc[(drafts.Player=='justin-jackson')&(drafts.College=='Maryland'),'DOB'].item()\n",
    "###\n",
    "Predraft_stats = Predraft_stats.loc[Predraft_stats.Date<Predraft_stats.Year] #elimate intl stats after draft day\n",
    "\n",
    "#force int64 to float64 for cooperation with statsmodel package\n",
    "for i in Predraft_stats.columns:\n",
    "    if Predraft_stats[i].dtype == 'Int64':\n",
    "        Predraft_stats[i] = Predraft_stats[i].astype('float64')\n",
    "        \n",
    "#save file\n",
    "Predraft_game_stats.to_csv(path+'Predraft_game_stats'+str(first_year)+'_'+str(last_year)+'.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predraft_game_stats_prior = pd.read_csv(path+'Predraft_game_stats.csv')\n",
    "Predraft_game_stats_current = pd.read_csv(path+'Predraft_game_stats'+str(first_year)+'_'+str(last_year)+'.csv')\n",
    "Predraft_game_stats = pd.concat([Predraft_game_stats_prior, Predraft_game_stats_current])\n",
    "Predraft_stats = Predraft_stats.drop([Predraft_stats.loc[Predraft_stats.MP.isnull()].index[0]], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble NBA gamelogs into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if drafts table needs to be loaded\n",
    "drafts = pd.read_csv(path+'drafts.csv')\n",
    "drafts['cbb_gamelogs'] = drafts['cbb_gamelogs'].apply(lambda x: eval(x))\n",
    "drafts['pro_gamelogs'] = drafts['pro_gamelogs'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticB3 = time.perf_counter()\n",
    "\n",
    "NBA_stats = [] #destination list\n",
    "\n",
    "for i in range(len(drafts)+1):\n",
    "    try:\n",
    "        for q in drafts.loc[i, 'pro_gamelogs']: #for each gamelog url\n",
    "            x = pd.read_html(q)[7] #get table\n",
    "            #conform column names\n",
    "            x.rename(columns={'Unnamed: 7':'W/L', 'Unnamed: 8':'W/L', 'Unnamed: 5':'Location', 'Unnamed: 3':'Location'}, inplace=True)\n",
    "            x.rename(columns=dict(zip(list(x.columns[x.columns.str.contains('Playoffs')==True]), cycle(['Date']))), inplace=True) \n",
    "            x['Player']=drafts.loc[i,'Player'] #get player name\n",
    "            x['DOB']=drafts.loc[i,'DOB'] #get DOB\n",
    "            if x.Rk.dtype != 'O':  #remove junk rows      \n",
    "                x = x.loc[x.Rk.isna()!=True]\n",
    "                NBA_stats.append(x)\n",
    "            else:\n",
    "                x = x.loc[x.Rk.str.isdigit()==True]\n",
    "                NBA_stats.append(x)\n",
    "    except:\n",
    "        pass \n",
    "    #print(i)\n",
    "NBA_game_stats = pd.concat(NBA_stats) #combine tables\n",
    "NBA_game_stats = NBA_game_stats.loc[NBA_game_stats.MP.str.match(r'[^0-9]')!=True]\n",
    "tocB3 = time.perf_counter()\n",
    "\n",
    "print(f\"{tocB3 - ticB3:0.4f} seconds\")  #revised\n",
    "\n",
    "#print(f\"{tocA3 - ticA3:0.4f} seconds\")  #original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NBA_game_stats.drop(['Unnamed: 31', 'League'], axis=1, inplace=True) #remove unneeded cols\n",
    "#NBA_game_stats['MP'] = NBA_game_stats['MP'].apply(lambda x: minplayed(x)) \n",
    "NBA_game_stats.Date = NBA_game_stats.Date.astype('datetime64')\n",
    "\n",
    "def ages(x): #convert age to float\n",
    "        a = float(x.split('-')[0])\n",
    "        b = float(x.split('-')[1])/365\n",
    "        return a+b\n",
    "\n",
    "NBA_game_stats['DOB'] = NBA_game_stats['DOB'].astype('datetime64')    \n",
    "#NBA_game_stats.loc[NBA_game_stats['Age'].isna()!=True,'Age'] = NBA_game_stats.loc[NBA_game_stats['Age'].isna()!=True,'Age'].apply(lambda x: ages(x))\n",
    "#NBA_game_stats = NBA_game_stats.merge(drafts[['Player', 'DOB', 'Year']], how = 'left', left_on=['Player'], right_on=['Player']) #Bring in DOB (eliminate)\n",
    "\n",
    "NBA_game_stats = NBA_game_stats.merge(drafts[['Player', 'DOB']], how = 'left', left_on=['Player', 'DOB'], right_on=['Player', 'DOB']) #Bring in DOB (keep)\n",
    "NBA_game_stats.loc[NBA_game_stats['Age'].isna()==True,'Age'] = ((NBA_game_stats.loc[NBA_game_stats.Age.isna()==True,'Date']-NBA_game_stats.loc[NBA_game_stats.Age.isna()==True,'DOB'])/np.timedelta64(1,'Y'))\n",
    "\n",
    "###To remove duplicate justin jackson - delete once after new webscrape\n",
    "#NBA_game_stats.drop(NBA_game_stats.loc[(NBA_game_stats.Player=='justin-jackson') & (NBA_game_stats.DOB==drafts.loc[(drafts.Player=='justin-jackson')&(drafts.College=='Maryland'),'DOB'].item())].index, axis=0, inplace=True)\n",
    "###\n",
    "NBA_game_stats['Years_pro'] = (NBA_game_stats.Date-NBA_game_stats.Year.astype('datetime64'))/np.timedelta64(1,'Y')\n",
    "NBA_game_stats.Years_pro = NBA_game_stats.Years_pro - NBA_game_stats.Years_pro.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erler\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (32,35,37,39,40,41,42,43,44) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#save file\n",
    "NBA_game_stats.to_csv(path+'NBAp'+str(first_year)+'_'+str(last_year)+'.csv', index=None) #save to folder in case failure\n",
    "NBA_game_stats_prior = pd.read_csv('C:/Users/erler/OneDrive/Documents/Random Data Sets/'+'NBA_game_stats.csv')\n",
    "NBAp_current = pd.read_csv('C:/Users/erler/OneDrive/Documents/Random Data Sets/'+'NBAp'+str(first_year)+'_'+str(last_year)+'.csv')\n",
    "\n",
    "NBA_game_stats = pd.concat([NBA_game_stats_prior, NBAp_current])\n",
    "#NBA_game_stats = NBA_game_stats.drop(['Unnamed: 0'], axis=1)\n",
    "NBA_game_stats.to_csv(path+'NBA_game_stats'+'.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NBA_game_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-fdc48f2700d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mNBA_game_stats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'NBA_game_stats'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'NBA_game_stats' is not defined"
     ]
    }
   ],
   "source": [
    "NBA_game_stats.to_csv(path+'NBA_game_stats'+'.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
